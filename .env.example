# ==============================================================================
# NEW: Simplified Configuration with config/models.yaml
# ==============================================================================
# Instead of editing this file, you can now use config/models.yaml for easier
# model configuration! Just set MODEL_PROFILE to switch between configurations:
#
#   MODEL_PROFILE=dev-fast      # Fast testing with mocks
#   MODEL_PROFILE=dev-accurate  # Real models, single process (no servers!)
#   MODEL_PROFILE=prod          # Distributed deployment with HTTP servers
#   MODEL_PROFILE=test          # All mocks for testing
#
# See config/models.yaml for available profiles and customization options.
#
# The variables below are still supported for backward compatibility.
# ==============================================================================

# Model Configuration Profile (if using config/models.yaml)
MODEL_PROFILE=dev-fast

# OpenRouter API Configuration
OPENROUTER_API_KEY=<your_openrouter_api_key>
OPENROUTER_MODEL=upstage/solar-pro-3:free
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1/chat/completions

# Lettuce Configuration (for HTTP backend mode or fallback)
LETTUCE_URL=http://127.0.0.1:8000
LETTUCE_GROUNDED_MIN=0.85
LETTUCE_SPAN_CONF=0.90
LETTUCE_PORT=8000
LETTUCE_MODEL=KRLabsOrg/lettucedect-base-modernbert-en-v1

# NLI Configuration (for HTTP backend mode or fallback)
NLI_URL=http://127.0.0.1:9000
NLI_CONTRADICTION_CONF=0.90
NLI_CHUNK_SIZE=2000
NLI_MODEL=upstage/solar-pro-3:free
NLI_PORT=9000
HALUGATE_URL=http://localhost:8000/validate
HALUGATE_GROUNDED_MIN=0.85
HALUGATE_CONTRADICTION_CONF=0.9
HALUGATE_MAX_SEVERITY=4
SEMANTIC_ROUTER_URL=http://localhost:8801/v1/chat/completions
SEMANTIC_ROUTER_MODEL=auto
